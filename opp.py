import streamlit as st
import requests
import datetime
import pandas as pd

# ==========================================
# è¨­å®šã‚¨ãƒªã‚¢
# ==========================================
OPENWEATHER_API_KEY = "f8b87c403597b305f1bbf48a3bdf8dcb"
STATION_CODE = "344311"  # ç«¹åŸ
TARGET_YEAR = 2026       # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå¹´

# å¤§è¥¿æ¸¯ è£œæ­£å®šæ•°
TIME_OFFSET_MIN = 1       # æ™‚é–“è£œæ­£ +1åˆ†
LEVEL_BASE_OFFSET = 13    # åŸºæº–é¢è£œæ­£ +13cm
STANDARD_PRESSURE = 1013  # æ¨™æº–æ°—åœ§

# ==========================================
# 1. ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ã‚¿ (1æœˆ9æ—¥ãƒ»4æ—¥å¯¾å¿œ)
# ==========================================
# æ°—è±¡åºã«ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã«è¡¨ç¤ºã™ã‚‹ãƒ‡ãƒ¼ã‚¿ (æ¯æ™‚æ½®ä½)
BACKUP_DATA_2026 = {
    "2026-01-09": [230, 275, 290, 265, 210, 140, 70, 30, 40, 100, 180, 260, 315, 330, 300, 240, 170, 110, 80, 85, 130, 190, 250, 290],
    "2026-01-04": [180, 100, 30, 0, 30, 100, 190, 280, 340, 360, 330, 270, 190, 110, 50, 30, 60, 120, 200, 270, 310, 300, 250, 180]
}

# ==========================================
# 2. ãƒ‡ãƒ¼ã‚¿å–å¾— & è§£æãƒ­ã‚¸ãƒƒã‚¯
# ==========================================
@st.cache_data(ttl=3600)
def fetch_jma_tide_data(year, station_code):
    """æ°—è±¡åºã‹ã‚‰æ¯æ™‚ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã€‚å¤±æ•—ã—ãŸã‚‰ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½¿ç”¨"""
    url = f"https://www.data.jma.go.jp/kaiyou/data/db/tide/suisan/txt/{year}/{station_code}.txt"
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }
    
    try:
        response = requests.get(url, headers=headers, timeout=5)
        response.encoding = 'utf-8'
        if response.status_code == 200:
            return parse_jma_text(response.text, year)
    except Exception:
        pass

    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
    fallback_map = {}
    for date_key, hourly_vals in BACKUP_DATA_2026.items():
        fallback_map[date_key] = hourly_vals
    return fallback_map

def parse_jma_text(text_data, year):
    data_map = {}
    lines = text_data.splitlines()
    for line in lines:
        parts = line.split()
        if len(parts) < 28 or not parts[0].isdigit():
            continue
        try:
            m_month = int(parts[2])
            m_day   = int(parts[3])
            date_str = f"{year}-{m_month:02d}-{m_day:02d}"
            hourly_levels = [int(h) for h in parts[4:28]]
            data_map[date_str] = hourly_levels
        except ValueError:
            continue
    return data_map

def get_current_pressure():
    lat, lon = 34.23, 132.83
    url = f"https://api.openweathermap.org/data/2.5/weather?lat={lat}&lon={lon}&appid={OPENWEATHER_API_KEY}&units=metric&lang=ja"
    try:
        res = requests.get(url, timeout=3)
        if res.status_code == 200:
            return res.json()["main"]["pressure"]
    except Exception:
        pass
    return STANDARD_PRESSURE

# ==========================================
# 3. è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯
# ==========================================
def calculate_workable_hours(hourly_tides, threshold, start_h, end_h, total_correction):
    """æŒ‡å®šæ™‚é–“å†…ã‹ã¤æŒ‡å®šæ½®ä½ä»¥ä¸‹ã®æ™‚é–“å¸¯ã‚’ç®—å‡º"""
    workable_ranges = []
    corrected_levels = [h + total_correction for h in hourly_tides]
    
    is_working = False
    start_time = None
    
    # æŒ‡å®šæ™‚é–“ç¯„å›²ã®ã¿ãƒã‚§ãƒƒã‚¯
    for h in range(24):
        # æ™‚é–“å¤–ã¯ã‚¹ã‚­ãƒƒãƒ—
        if h < start_h or h > end_h:
            if is_working: # æ™‚é–“åˆ‡ã‚Œã§ä½œæ¥­çµ‚äº†
                workable_ranges.append(f"{start_time:02d}:00 ï½ {h:02d}:00")
                is_working = False
            continue
            
        level = corrected_levels[h]
        
        if level <= threshold:
            if not is_working:
                is_working = True
                start_time = h
        else:
            if is_working:
                workable_ranges.append(f"{start_time:02d}:00 ï½ {h:02d}:00")
                is_working = False
                
    if is_working:
        workable_ranges.append(f"{start_time:02d}:00 ï½ {end_h + 1 if end_h < 23 else 24}:00")
        
    return workable_ranges, corrected_levels

def get_peaks_df(hourly_corrected):
    """æº€å¹²æ½®ã®è¡¨ã‚’ä½œæˆ"""
    peaks = []
    for i in range(1, 23):
        prev, curr, next_val = hourly_corrected[i-1], hourly_corrected[i], hourly_corrected[i+1]
        
        # æ™‚é–“è£œæ­£ (+1åˆ†) ã‚’ã“ã“ã§é©ç”¨
        total_m = i * 60 + TIME_OFFSET_MIN
        time_str = f"{(total_m // 60):02d}:{total_m % 60:02d}"
        
        if prev < curr and curr >= next_val:
            peaks.append({"æ™‚åˆ»": time_str, "æ½®ä½": f"{curr} cm", "æ½®å": "æº€æ½®"})
        elif prev > curr and curr <= next_val:
            peaks.append({"æ™‚åˆ»": time_str, "æ½®ä½": f"{curr} cm", "æ½®å": "å¹²æ½®"})
    return pd.DataFrame(peaks)

# ==========================================
# 4. ãƒ¡ã‚¤ãƒ³ç”»é¢
# ==========================================
def main():
    st.set_page_config(page_title="å¤§è¥¿æ¸¯ æ½®æ±äºˆæ¸¬", page_icon="ğŸŒŠ")
    st.title("ğŸŒŠ å¤§è¥¿æ¸¯ (å¤§å´ä¸Šå³¶) æ½®æ±äºˆæ¸¬")
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
    with st.sidebar:
        st.header("âš™ï¸ è¨­å®š")
        # æ—¥ä»˜é¸æŠ
        default_date = datetime.date(2026, 1, 9)
        selected_date = st.date_input("æ—¥ä»˜", default_date)
        date_str = selected_date.strftime("%Y-%m-%d")
        
        st.divider()
        st.subheader("ğŸ›  ä½œæ¥­åˆ¤å®šæ¡ä»¶")
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ 120cm
        work_threshold = st.slider("æ½®ä½ãƒ©ã‚¤ãƒ³ (cmä»¥ä¸‹)", 0, 400, 120)
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ 7:00 - 23:00
        work_time_range = st.slider("ä½œæ¥­æ™‚é–“å¸¯", 0, 24, (7, 23))

    # ãƒ‡ãƒ¼ã‚¿å–å¾—
    with st.spinner("ãƒ‡ãƒ¼ã‚¿æ›´æ–°ä¸­..."):
        tide_db = fetch_jma_tide_data(TARGET_YEAR, STATION_CODE)
        current_hpa = get_current_pressure()
    
    # è£œæ­£å€¤
    pressure_diff = STANDARD_PRESSURE - current_hpa
    total_level_correction = LEVEL_BASE_OFFSET + pressure_diff

    # ãƒ˜ãƒƒãƒ€ãƒ¼æƒ…å ±è¡¨ç¤º
    c1, c2 = st.columns(2)
    c1.metric("ç¾åœ¨æ°—åœ§", f"{current_hpa} hPa")
    c2.metric("ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è£œæ­£", f"{total_level_correction:+} cm", help="åŸºæº–13cm + æ°—åœ§å·®")
    st.divider()

    # ãƒ‡ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯
    if not tide_db or date_str not in tide_db:
        st.error(f"âŒ {date_str} ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        st.info("â€»ãƒ‡ãƒ¢ç”¨ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹ 2026-01-04 ã¾ãŸã¯ 2026-01-09 ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        return

    hourly_tides = tide_db[date_str]
    
    # ä½œæ¥­æ™‚é–“è¨ˆç®—
    start_h, end_h = work_time_range
    work_times, corrected_levels = calculate_workable_hours(
        hourly_tides, work_threshold, start_h, end_h, total_level_correction
    )

    # === ãƒ¡ã‚¤ãƒ³è¡¨ç¤º 1: ä½œæ¥­åˆ¤å®š ===
    st.subheader(f"âœ… ä½œæ¥­å¯èƒ½æ™‚é–“ ({start_h}:00-{end_h}:00 / {work_threshold}cmä»¥ä¸‹)")
    if work_times:
        for wt in work_times:
            st.success(f"ğŸ•’ {wt}")
    else:
        st.warning("âš ï¸ æ¡ä»¶ã«åˆã†ä½œæ¥­æ™‚é–“ã¯ã‚ã‚Šã¾ã›ã‚“")

    # === ãƒ¡ã‚¤ãƒ³è¡¨ç¤º 2: æ½®æ±è¡¨ (å…ƒã®è¡¨ç¤ºã‚’å¾©æ—§) ===
    st.subheader("ğŸ“… æº€æ½®ãƒ»å¹²æ½®ãƒªã‚¹ãƒˆ")
    df_peaks = get_peaks_df(corrected_levels)
    st.dataframe(
        df_peaks,
        use_container_width=True,
        hide_index=True
    )

    # === ãƒ¡ã‚¤ãƒ³è¡¨ç¤º 3: ã‚°ãƒ©ãƒ• ===
    st.caption("ğŸ“ˆ æ½®ä½ã‚°ãƒ©ãƒ• (èµ¤ç·š: ä½œæ¥­ãƒ©ã‚¤ãƒ³)")
    chart_df = pd.DataFrame({
        "æ™‚åˆ»": [f"{h:02d}:00" for h in range(24)],
        "æ½®ä½": corrected_levels,
        "ä½œæ¥­ãƒ©ã‚¤ãƒ³": [work_threshold] * 24
    })
    st.line_chart(chart_df.set_index("æ™‚åˆ»"), color=["#0000FF", "#FF0000"])

if __name__ == "__main__":
    main()
