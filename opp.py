import streamlit as st
import datetime
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import requests
import numpy as np
import math

# ==========================================
# 1. ã‚¢ãƒ—ãƒªè¨­å®š & å®šæ•°å®šç¾©
# ==========================================
st.set_page_config(layout="wide", page_title="Onishi Tide Forecast")

# APIã‚­ãƒ¼ (OpenWeatherMap)
OWM_API_KEY = "f8b87c403597b305f1bbf48a3bdf8dcb"

# è£œæ­£ãƒ­ã‚¸ãƒƒã‚¯å®šæ•°
TIME_OFFSET_MIN = 1       # æ™‚é–“è£œæ­£ +1åˆ†
LEVEL_BASE_OFFSET = 13    # åŸºæº–é¢è£œæ­£ +13cm
STANDARD_PRESSURE = 1013  # æ¨™æº–æ°—åœ§

# ==========================================
# 2. ã‚¹ã‚¿ã‚¤ãƒ« & ãƒ•ã‚©ãƒ³ãƒˆè¨­å®š (æ–‡å­—åŒ–ã‘å¯¾ç­–)
# ==========================================
st.markdown("""
<style>
    div.stButton > button { width: 100%; height: 3.0rem; font-size: 1rem; margin-top: 0px; }
    [data-testid="column"] { min-width: 0px !important; flex: 1 !important; }
    .block-container { padding-top: 1rem; padding-bottom: 2rem; }
    h5 { margin-bottom: 0px; }
</style>
""", unsafe_allow_html=True)

# ã€é‡è¦ã€‘ãƒ•ã‚©ãƒ³ãƒˆè¨­å®šã‚’ãƒªã‚»ãƒƒãƒˆã—ã¦ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«æˆ»ã™ï¼ˆâ–¡åŒ–ã‘å›é¿ã®æœ€å–„ç­–ï¼‰
# ã‚°ãƒ©ãƒ•å†…ã®æ–‡å­—ã¯ã™ã¹ã¦ASCII(è‹±èª)ã«ã—ã¾ã™
plt.rcParams.update(plt.rcParamsDefault)

# ==========================================
# 3. ãƒ‡ãƒ¼ã‚¿å–å¾— (API & æ°—è±¡åº)
# ==========================================

@st.cache_data(ttl=3600)
def get_current_pressure():
    lat, lon = 34.234, 132.831
    url = f"https://api.openweathermap.org/data/2.5/weather?lat={lat}&lon={lon}&appid={OWM_API_KEY}&units=metric"
    try:
        res = requests.get(url, timeout=3)
        if res.status_code == 200:
            return float(res.json()['main']['pressure'])
    except:
        pass
    return 1013.0

@st.cache_data(ttl=3600)
def fetch_jma_data_map(year):
    url = f"https://www.data.jma.go.jp/kaiyou/data/db/tide/suisan/txt/{year}/344311.txt"
    headers = {"User-Agent": "Mozilla/5.0"}
    data_map = {}
    try:
        res = requests.get(url, headers=headers, timeout=5)
        if res.status_code == 200:
            lines = res.text.splitlines()
            for line in lines:
                parts = line.split()
                if len(parts) < 28 or not parts[0].isdigit(): continue
                m, d = int(parts[2]), int(parts[3])
                date_str = f"{year}-{m:02d}-{d:02d}"
                levels = [int(h) for h in parts[4:28]]
                data_map[date_str] = levels
    except:
        pass
    return data_map

# ==========================================
# 4. é«˜ç²¾åº¦ã‚¹ãƒ—ãƒ©ã‚¤ãƒ³è£œé–“ (Catmull-Rom Spline)
# ==========================================
# Scipyã‚’ä½¿ã‚ãšã«ã€ç‚¹ã¨ç‚¹ã‚’è‡ªç„¶ãªæ›²ç·šã§ã¤ãªãæ•°å­¦ãƒ­ã‚¸ãƒƒã‚¯ã§ã™ã€‚
# ã‚«ã‚¯ã‚«ã‚¯ã‚„ä¸è‡ªç„¶ãªå¹³å¦ã•ã‚’å®Œå…¨ã«è§£æ¶ˆã—ã¾ã™ã€‚

def catmull_rom_spline(p0, p1, p2, p3, n_points=60):
    """4ç‚¹ p0, p1, p2, p3 ã‹ã‚‰ p1-p2é–“ã®æ›²ç·šã‚’ç”Ÿæˆã™ã‚‹"""
    t = np.linspace(0, 1, n_points)
    t2 = t * t
    t3 = t2 * t
    
    # Catmull-Rom ä¿‚æ•°è¡Œåˆ—
    v0 = (p2 - p0) * 0.5
    v1 = (p3 - p1) * 0.5
    
    # 3æ¬¡å¤šé …å¼ã®è¨ˆç®—
    a = 2*p1 - 2*p2 + v0 + v1
    b = -3*p1 + 3*p2 - 2*v0 - v1
    c = v0
    d = p1
    
    return a*t3 + b*t2 + c*t + d

def generate_smooth_curve(timestamps, hourly_levels, resolution_min=1):
    """æ¯æ™‚ãƒ‡ãƒ¼ã‚¿ã‚’Catmull-Romã‚¹ãƒ—ãƒ©ã‚¤ãƒ³ã§åˆ†å˜ä½ã«ãªã‚ã‚‰ã‹ã«ã™ã‚‹"""
    
    # ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™ (å‰å¾Œã®åˆ¶å¾¡ç‚¹ç”¨ã«ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°)
    y = hourly_levels
    # å…ˆé ­ã¨æœ«å°¾ã‚’è¤‡è£½ã—ã¦åˆ¶å¾¡ç‚¹ã‚’ç¢ºä¿
    y_padded = [y[0]] + y + [y[-1]]
    
    smooth_times = []
    smooth_levels = []
    
    # å„åŒºé–“ã‚’è£œé–“
    for i in range(len(y) - 1):
        # åˆ¶å¾¡ç‚¹4ã¤: p0, p1(ç¾åœ¨), p2(æ¬¡), p3
        p0, p1, p2, p3 = y_padded[i], y_padded[i+1], y_padded[i+2], y_padded[i+3]
        
        # 1æ™‚é–“åˆ†ã®æ›²ç·šãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ (60å€‹ã®ç‚¹)
        segment_levels = catmull_rom_spline(p0, p1, p2, p3, n_points=60)
        
        # æ™‚åˆ»ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
        t_start = timestamps[i]
        segment_times = [t_start + datetime.timedelta(minutes=m) for m in range(60)]
        
        smooth_levels.extend(segment_levels)
        smooth_times.extend(segment_times)
    
    # æœ€å¾Œã®ç‚¹ã‚’è¿½åŠ 
    smooth_times.append(timestamps[-1])
    smooth_levels.append(hourly_levels[-1])
    
    return pd.DataFrame({"time": smooth_times, "level": smooth_levels})

# ==========================================
# 5. ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
# ==========================================
def get_moon_age(date_obj):
    base = datetime.date(2000, 1, 6)
    return ((date_obj - base).days) % 29.53059

def get_tide_name(moon_age):
    m = int(moon_age)
    if m >= 30: m -= 30
    if 0<=m<=2 or 14<=m<=17 or 29<=m<=30: return "å¤§æ½®"
    elif 3<=m<=5 or 18<=m<=20: return "ä¸­æ½®"
    elif 6<=m<=9 or 21<=m<=24: return "å°æ½®"
    elif 10<=m<=12: return "é•·æ½®"
    elif m==13 or 25<=m<=28: return "è‹¥æ½®"
    return "ä¸­æ½®"

def deduplicate_peaks(df_peaks, min_dist_mins=60):
    if df_peaks.empty: return df_peaks
    keep = []
    last_time = None
    for idx, row in df_peaks.iterrows():
        if last_time is None or (row['time'] - last_time).total_seconds()/60 > min_dist_mins:
            keep.append(idx)
            last_time = row['time']
    return df_peaks.loc[keep]

# ==========================================
# 6. ãƒ¡ã‚¤ãƒ³äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚¯ãƒ©ã‚¹
# ==========================================
class OnishiTideModel:
    def __init__(self, pressure_hpa, year=2026):
        self.jma_map = fetch_jma_data_map(year)
        self.pressure_correction = int(STANDARD_PRESSURE - pressure_hpa)
        self.total_level_offset = LEVEL_BASE_OFFSET + self.pressure_correction
        self.time_offset = TIME_OFFSET_MIN
    
    def get_backup_level(self, dt):
        """ãƒ‡ãƒ¼ã‚¿ä¸è¶³æ™‚ã®æ•°å¼ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ— (ã“ã‚Œã‚‚æ»‘ã‚‰ã‹)"""
        epoch = datetime.datetime(2026, 1, 1, 0, 0)
        delta_h = (dt - epoch).total_seconds() / 3600.0
        level = 180 
        level += 110 * math.cos(2 * math.pi * delta_h / 12.42 - 1.0) 
        level += 40 * math.cos(2 * math.pi * delta_h / 24.0 - 2.0)
        return int(level)

    def get_dataframe(self, start_date, days=5):
        timestamps_hourly = []
        levels_hourly = []
        
        start_dt = datetime.datetime.combine(start_date, datetime.time(0, 0))
        # ã‚¹ãƒ—ãƒ©ã‚¤ãƒ³è£œé–“ã®ãŸã‚ã«å‰å¾Œã®ä½™åˆ†ãªãƒ‡ãƒ¼ã‚¿ã‚‚å«ã‚ã¦å–å¾—
        calc_start = start_dt - datetime.timedelta(hours=2)
        calc_end = start_dt + datetime.timedelta(days=days) + datetime.timedelta(hours=2)
        
        curr = calc_start
        while curr <= calc_end:
            d_str = curr.strftime("%Y-%m-%d")
            hour = curr.hour
            val = None
            if d_str in self.jma_map:
                try: val = self.jma_map[d_str][hour]
                except: pass
            if val is None:
                val = self.get_backup_level(curr)
            
            final_val = val + self.total_level_offset
            # æ™‚é–“è£œæ­£é©ç”¨
            t_point = curr + datetime.timedelta(minutes=self.time_offset)
            
            timestamps_hourly.append(t_point)
            levels_hourly.append(final_val)
            curr += datetime.timedelta(hours=1)
            
        # ã‚¹ãƒ—ãƒ©ã‚¤ãƒ³è£œé–“ã§ãªã‚ã‚‰ã‹ã«ã™ã‚‹
        df_smooth = generate_smooth_curve(timestamps_hourly, levels_hourly)
        
        # è¡¨ç¤ºæœŸé–“ã®ã¿åˆ‡ã‚Šå‡ºã—
        mask = (df_smooth['time'] >= start_dt) & (df_smooth['time'] < (start_dt + datetime.timedelta(days=days)))
        return df_smooth.loc[mask].reset_index(drop=True)

    def get_current_level(self, df_fine):
        now_jst = datetime.datetime.now(datetime.timezone.utc) + datetime.timedelta(hours=9)
        now_naive = now_jst.replace(tzinfo=None)
        if df_fine.empty or now_naive < df_fine['time'].iloc[0] or now_naive > df_fine['time'].iloc[-1]:
            return now_naive, self.get_backup_level(now_naive) + self.total_level_offset
        idx = (df_fine['time'] - now_naive).abs().idxmin()
        return now_naive, df_fine.loc[idx, 'level']

# ==========================================
# 7. UIè¡¨ç¤ºãƒ»å®Ÿè¡Œéƒ¨
# ==========================================
if 'view_date' not in st.session_state:
    now_jst = datetime.datetime.now(datetime.timezone.utc) + datetime.timedelta(hours=9)
    if now_jst.year != 2026:
        st.session_state['view_date'] = datetime.date(2026, 1, 9)
    else:
        st.session_state['view_date'] = now_jst.date()

view_date = st.session_state['view_date']
st.markdown("<h5 style='margin-bottom:5px;'>âš“ å¤§è¥¿æ¸¯ æ½®æ±ãƒ»ä½œæ¥­äºˆå ±</h5>", unsafe_allow_html=True)

# ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
current_pressure = get_current_pressure()
model = OnishiTideModel(pressure_hpa=current_pressure, year=2026)
df = model.get_dataframe(view_date, days=5)
curr_time, curr_lvl = model.get_current_level(df)

ma = get_moon_age(view_date)
tn = get_tide_name(ma)
p_diff = int(1013 - current_pressure)
adj_txt = f"+{p_diff}" if p_diff > 0 else f"{p_diff}"

st.markdown(f"""
<div style="font-size:0.9rem; background:#f8f9fa; padding:10px; border:1px solid #ddd; margin-bottom:10px; border-radius:5px;">
 <div><b>æœŸé–“:</b> {view_date.strftime('%Y/%m/%d')} ï½ (5æ—¥é–“) <span style="color:#555; margin-left:10px;">æœˆé½¢:{ma:.1f} ({tn})</span></div>
 <div style="margin-top:5px;">
   <span style="color:#0066cc; font-weight:bold; font-size:1.1rem;">ç¾åœ¨: {curr_time.strftime('%H:%M')} / {int(curr_lvl)}cm</span>
   <div style="font-size:0.8rem; color:#666; margin-top:3px;">
    æ°—åœ§:{int(current_pressure)}hPa (<span style="color:#d62728;">{adj_txt}cm</span>) + åœ°å½¢å·® <span style="color:#2ca02c;">+13cm</span>
   </div>
 </div>
</div>
""", unsafe_allow_html=True)

# ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³
c1, c2 = st.columns([1,1])
if c1.button("å‰ã®5æ—¥é–“ <"): st.session_state['view_date'] -= datetime.timedelta(days=5)
if c2.button("> æ¬¡ã®5æ—¥é–“"): st.session_state['view_date'] += datetime.timedelta(days=5)

# ã‚µã‚¤ãƒ‰ãƒãƒ¼
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    st.info(f"æ°—åœ§: {current_pressure} hPa")
    st.markdown("---")
    target_cm = st.number_input("ä½œæ¥­å¯èƒ½æ½®ä½ (cmä»¥ä¸‹)", value=120, step=10)
    start_h, end_h = st.slider("ä½œæ¥­æ™‚é–“å¸¯", 0, 24, (7, 23))
    st.markdown("---")
    if st.button("åŸºæº–æ—¥ (2026/1/9)"): st.session_state['view_date'] = datetime.date(2026, 1, 9)

# ä½œæ¥­å¯èƒ½åˆ¤å®š
df['hour'] = df['time'].dt.hour
df['is_safe'] = (df['level'] <= target_cm) & (df['hour'] >= start_h) & (df['hour'] < end_h)

safe_windows = []
if df['is_safe'].any():
    df['grp'] = (df['is_safe'] != df['is_safe'].shift()).cumsum()
    for _, g in df[df['is_safe']].groupby('grp'):
        s, e = g['time'].iloc[0], g['time'].iloc[-1]
        if (e-s).total_seconds() >= 600:
            min_l = g['level'].min()
            min_t = g.loc[g['level'].idxmin(), 'time']
            d = e - s
            h, m = d.seconds//3600, (d.seconds%3600)//60
            
            safe_windows.append({
                "æ—¥ä»˜": s.strftime('%m/%d(%a)'),
                "é–‹å§‹": s.strftime("%H:%M"),
                "çµ‚äº†": e.strftime("%H:%M"),
                "æ™‚é–“": f"{h}:{m:02}",
                "gl": f"Work\n{h}:{m:02}", # ã‚°ãƒ©ãƒ•ç”¨ã¯è‹±èª
                "mt": min_t, "ml": min_l
            })

# ãƒ”ãƒ¼ã‚¯æ¤œå‡º
peak_window = 60
df['is_high'] = False
df['is_low'] = False
levels_arr = df['level'].values
# ç«¯ã®å‡¦ç†ã‚¨ãƒ©ãƒ¼é˜²æ­¢
l_len = len(levels_arr)
for i in range(peak_window, l_len-peak_window):
    window = levels_arr[i-peak_window : i+peak_window+1]
    center = levels_arr[i]
    if center == np.max(window) and center > 150:
        df.at[i, 'is_high'] = True
    if center == np.min(window) and center < 250:
        df.at[i, 'is_low'] = True

highs = deduplicate_peaks(df[df['is_high']].copy())
lows = deduplicate_peaks(df[df['is_low']].copy())

# ==========================================
# 8. ã‚°ãƒ©ãƒ•æç”»
# ==========================================
fig, ax = plt.subplots(figsize=(10, 5))

# ãƒ¡ã‚¤ãƒ³ç·š (ã‚¹ãƒ—ãƒ©ã‚¤ãƒ³è£œé–“ã§æ»‘ã‚‰ã‹)
ax.plot(df['time'], df['level'], '#0066cc', lw=2, zorder=2, label="Level")
ax.axhline(target_cm, c='orange', ls='--', lw=1.5, label='Limit')
ax.fill_between(df['time'], df['level'], target_cm, where=df['is_safe'], color='#ffcc00', alpha=0.4)

# ç¾åœ¨ä½ç½®
gs, ge = df['time'].iloc[0], df['time'].iloc[-1]
if gs <= curr_time <= ge:
    ax.scatter(curr_time, curr_lvl, c='gold', edgecolors='black', s=100, zorder=10)

# æº€æ½®ãƒãƒ¼ã‚¯ (æ–‡å­—ã¯è‹±èª/æ•°å­—ã®ã¿)
for _, r in highs.iterrows():
    ax.scatter(r['time'], r['level'], c='red', marker='^', s=40, zorder=3)
    off = 15 if r['time'].day % 2 == 0 else 35
    ax.annotate(f"{r['time'].strftime('%H:%M')}\n{int(r['level'])}", 
                (r['time'], r['level']), xytext=(0,off), textcoords='offset points', 
                ha='center', fontsize=8, color='#cc0000', fontweight='bold')

# å¹²æ½®ãƒãƒ¼ã‚¯
for _, r in lows.iterrows():
    ax.scatter(r['time'], r['level'], c='blue', marker='v', s=40, zorder=3)
    off = -25 if r['time'].day % 2 == 0 else -45
    ax.annotate(f"{r['time'].strftime('%H:%M')}\n{int(r['level'])}", 
                (r['time'], r['level']), xytext=(0,off), textcoords='offset points', 
                ha='center', fontsize=8, color='#0000cc', fontweight='bold')

# ä½œæ¥­ãƒ©ãƒ™ãƒ« (Work)
for w in safe_windows:
    ax.annotate(w['gl'], (w['mt'], w['ml']), xytext=(0,-85), textcoords='offset points', 
                ha='center', fontsize=8, color='#b8860b', fontweight='bold', 
                bbox=dict(boxstyle="square,pad=0.1", fc="white", ec="none", alpha=0.7))

# è»¸ãƒ©ãƒ™ãƒ« (è‹±èª)
ax.set_ylabel("Level (cm)")
ax.grid(True, ls=':', alpha=0.6)
ax.xaxis.set_major_formatter(mdates.DateFormatter('%m/%d\n(%a)'))
ax.set_ylim(bottom=df['level'].min() - 30, top=df['level'].max() + 50)

plt.tight_layout()
st.pyplot(fig)

# ==========================================
# 9. ä½œæ¥­æ™‚é–“ãƒªã‚¹ãƒˆè¡¨ç¤º (æ—¥æœ¬èªOK)
# ==========================================
st.markdown("---")
st.markdown(f"##### ğŸ“‹ ä½œæ¥­å¯èƒ½æ™‚é–“ãƒªã‚¹ãƒˆ (æ½®ä½ {target_cm}cmä»¥ä¸‹)")

if safe_windows:
    # ã‚°ãƒ©ãƒ•è¡¨ç¤ºç”¨ã«ä½œã£ãŸè¾æ›¸ãƒªã‚¹ãƒˆã‚’DataFrameåŒ–
    rdf = pd.DataFrame(safe_windows)
    
    # å¿…è¦ãªåˆ—ã ã‘æŠ½å‡º (æ—¥æœ¬èªã‚«ãƒ©ãƒ )
    display_cols = ["æ—¥ä»˜", "é–‹å§‹", "çµ‚äº†", "æ™‚é–“"]
    rdf_display = rdf[display_cols]
    
    cc = st.columns(3)
    chunks = np.array_split(rdf_display, 3)
    for i, col in enumerate(cc):
        if i < len(chunks) and not chunks[i].empty:
            col.dataframe(chunks[i], hide_index=True, use_container_width=True)
else:
    st.warning("ã“ã®æœŸé–“ã«ä½œæ¥­å¯èƒ½ãªæ™‚é–“å¸¯ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
