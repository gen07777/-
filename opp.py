import streamlit as st
import datetime
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import requests
import numpy as np
import math

# ---------------------------------------------------------
# 1. ã‚¢ãƒ—ãƒªè¨­å®š & å®šæ•°
# ---------------------------------------------------------
st.set_page_config(layout="wide", page_title="Onishi Port Precision Tide")
OWM_API_KEY = "f8b87c403597b305f1bbf48a3bdf8dcb"

# å¤§è¥¿æ¸¯ (å¤§å´ä¸Šå³¶) è£œæ­£å®šæ•°
TIME_OFFSET_MIN = 1       # æ™‚é–“è£œæ­£ +1åˆ†
LEVEL_BASE_OFFSET = 13    # åŸºæº–é¢è£œæ­£ +13cm
STANDARD_PRESSURE = 1013  # æ¨™æº–æ°—åœ§

# ---------------------------------------------------------
# 2. ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ & ã‚¹ã‚¿ã‚¤ãƒ«
# ---------------------------------------------------------
st.markdown("""
<style>
    div.stButton > button { width: 100%; height: 3.0rem; font-size: 1rem; margin-top: 0px; }
    [data-testid="column"] { min-width: 0px !important; flex: 1 !important; }
    .block-container { padding-top: 1rem; padding-bottom: 2rem; }
    h5 { margin-bottom: 0px; }
</style>
""", unsafe_allow_html=True)

def configure_font():
    plt.rcParams['font.family'] = 'sans-serif'
configure_font()

# ---------------------------------------------------------
# 3. ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ­ã‚¸ãƒƒã‚¯ (æ°—è±¡åº + OWM)
# ---------------------------------------------------------

# æ°—åœ§å–å¾—
@st.cache_data(ttl=3600)
def get_current_pressure():
    lat, lon = 34.234, 132.831
    url = f"https://api.openweathermap.org/data/2.5/weather?lat={lat}&lon={lon}&appid={OWM_API_KEY}&units=metric"
    try:
        res = requests.get(url, timeout=3)
        if res.status_code == 200:
            return float(res.json()['main']['pressure'])
    except:
        pass
    return 1013.0

# æ°—è±¡åºãƒ‡ãƒ¼ã‚¿å–å¾— & è§£æ
@st.cache_data(ttl=3600)
def fetch_jma_data_map(year):
    """æ°—è±¡åºã®TXTãƒ‡ãƒ¼ã‚¿ã‚’è¾æ›¸{æ—¥ä»˜: [0-23æ™‚ã®æ½®ä½]}ã«å¤‰æ›"""
    url = f"https://www.data.jma.go.jp/kaiyou/data/db/tide/suisan/txt/{year}/344311.txt" # ç«¹åŸ
    headers = {"User-Agent": "Mozilla/5.0"}
    data_map = {}
    try:
        res = requests.get(url, headers=headers, timeout=5)
        if res.status_code == 200:
            lines = res.text.splitlines()
            for line in lines:
                parts = line.split()
                if len(parts) < 28 or not parts[0].isdigit(): continue
                m, d = int(parts[2]), int(parts[3])
                date_str = f"{year}-{m:02d}-{d:02d}"
                levels = [int(h) for h in parts[4:28]]
                data_map[date_str] = levels
    except:
        pass
    return data_map

# ---------------------------------------------------------
# 4. æ•°å­¦çš„è£œé–“ãƒ­ã‚¸ãƒƒã‚¯ (Scipyä¸è¦ã®æ»‘ã‚‰ã‹è£œé–“)
# ---------------------------------------------------------
def cosine_interpolate(y1, y2, mu):
    """ã‚³ã‚µã‚¤ãƒ³è£œé–“: ç›´ç·šã§ã¯ãªãæ³¢ã®ã‚ˆã†ã«æ»‘ã‚‰ã‹ã«ã¤ãªã"""
    mu2 = (1 - math.cos(mu * math.pi)) / 2
    return (y1 * (1 - mu2) + y2 * mu2)

def generate_smooth_curve(timestamps, hourly_levels, interval_minutes=5):
    """æ¯æ™‚ã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚³ã‚µã‚¤ãƒ³è£œé–“ã§åˆ†å˜ä½ã«æ»‘ã‚‰ã‹ã«ã™ã‚‹"""
    smooth_times = []
    smooth_levels = []
    
    # ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆé–“ã‚’è£œé–“
    for i in range(len(timestamps) - 1):
        t_start = timestamps[i]
        t_end = timestamps[i+1]
        y_start = hourly_levels[i]
        y_end = hourly_levels[i+1]
        
        # é–“éš”ã”ã¨ã®ã‚¹ãƒ†ãƒƒãƒ—æ•°
        steps = int((t_end - t_start).total_seconds() / 60 / interval_minutes)
        if steps == 0: steps = 1
        
        for s in range(steps):
            mu = s / steps
            interp_y = cosine_interpolate(y_start, y_end, mu)
            interp_t = t_start + datetime.timedelta(minutes=s*interval_minutes)
            
            smooth_times.append(interp_t)
            smooth_levels.append(interp_y)
            
    # æœ€å¾Œã®ç‚¹ã‚’è¿½åŠ 
    smooth_times.append(timestamps[-1])
    smooth_levels.append(hourly_levels[-1])
    
    return pd.DataFrame({"time": smooth_times, "level": smooth_levels})

# ---------------------------------------------------------
# 5. ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
# ---------------------------------------------------------
def get_moon_age(date_obj):
    base = datetime.date(2000, 1, 6)
    return ((date_obj - base).days) % 29.53059

def get_tide_name(moon_age):
    m = int(moon_age)
    if m >= 30: m -= 30
    if 0<=m<=2 or 14<=m<=17 or 29<=m<=30: return "å¤§æ½® (Spring)"
    elif 3<=m<=5 or 18<=m<=20: return "ä¸­æ½® (Middle)"
    elif 6<=m<=9 or 21<=m<=24: return "å°æ½® (Neap)"
    elif 10<=m<=12: return "é•·æ½® (Long)"
    elif m==13 or 25<=m<=28: return "è‹¥æ½® (Young)"
    return "ä¸­æ½® (Middle)"

def deduplicate_peaks(df_peaks, min_dist_mins=60):
    if df_peaks.empty: return df_peaks
    keep = []
    last_time = None
    for idx, row in df_peaks.iterrows():
        if last_time is None or (row['time'] - last_time).total_seconds()/60 > min_dist_mins:
            keep.append(idx)
            last_time = row['time']
    return df_peaks.loc[keep]

# ---------------------------------------------------------
# 6. æ–°ãƒ»æ½®æ±ãƒ¢ãƒ‡ãƒ« (ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆéƒ¨)
# ---------------------------------------------------------
class JMATideModel:
    def __init__(self, pressure_hpa, year=2026):
        self.jma_map = fetch_jma_data_map(year)
        self.pressure_correction = int(STANDARD_PRESSURE - pressure_hpa) # å¸ã„ä¸Šã’åŠ¹æœ
        self.total_level_offset = LEVEL_BASE_OFFSET + self.pressure_correction
        self.time_offset = TIME_OFFSET_MIN
    
    def get_backup_level(self, dt):
        """
        ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã®ãƒ‡ãƒ¢ç”¨: æ•°å¼ã§æ½®ä½ã‚’ç”Ÿæˆã™ã‚‹ï¼ˆã ã‹ã‚‰æ»‘ã‚‰ã‹ï¼‰
        åŸºæº–: å¹³å‡180cm, æŒ¯å¹…140cm, å‘¨æœŸç´„12.4æ™‚é–“
        """
        # åŸºæº–æ™‚åˆ»ã‹ã‚‰ã®çµŒéæ™‚é–“(æ™‚é–“å˜ä½)
        epoch = datetime.datetime(2026, 1, 1, 0, 0)
        delta_h = (dt - epoch).total_seconds() / 3600.0
        
        # ç°¡æ˜“èª¿å’Œåˆ†è§£ãƒ¢ãƒ‡ãƒ« (M2 + K1ç›¸å½“)
        # ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ‡ãƒ¼ã‚¿åˆ‡ã‚Œã§ã‚‚ã€Œä¸è‡ªç„¶ãªæ®µå·®ã€ãŒçµ¶å¯¾ã«ç™ºç”Ÿã—ãªã„
        level = 180 
        level += 110 * math.cos(2 * math.pi * delta_h / 12.42 - 1.0) # åŠæ—¥å‘¨æ½®
        level += 40 * math.cos(2 * math.pi * delta_h / 24.0 - 2.0)   # æ—¥å‘¨æ½®
        return int(level)

    def get_dataframe(self, start_date, days=10):
        # 1. ã¾ãšã€Œæ¯æ™‚ã€ã®ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã‚’ä½œã‚‹
        timestamps_hourly = []
        levels_hourly = []
        
        start_dt = datetime.datetime.combine(start_date, datetime.time(0, 0))
        end_dt = start_dt + datetime.timedelta(days=days)
        
        curr = start_dt
        while curr <= end_dt: # æœ€å¾Œã®æ™‚é–“ã¾ã§å«ã‚ã‚‹
            d_str = curr.strftime("%Y-%m-%d")
            hour = curr.hour
            
            val = None
            # A. æ°—è±¡åºãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆ
            if d_str in self.jma_map:
                try:
                    val = self.jma_map[d_str][hour]
                except:
                    pass
            
            # B. ãªã„å ´åˆ (ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ•°å¼ã‚’ä½¿ç”¨)
            if val is None:
                val = self.get_backup_level(curr)
            
            # è£œæ­£é©ç”¨
            final_val = val + self.total_level_offset
            
            # æ™‚é–“é©ç”¨ (ç«¹åŸãƒ‡ãƒ¼ã‚¿ + 1åˆ†)
            t_point = curr + datetime.timedelta(minutes=self.time_offset)
            
            timestamps_hourly.append(t_point)
            levels_hourly.append(final_val)
            
            curr += datetime.timedelta(hours=1)
            
        # 2. æ¯æ™‚ã®ãƒ‡ãƒ¼ã‚¿ã‚’ã€Œã‚³ã‚µã‚¤ãƒ³è£œé–“ã€ã§æ»‘ã‚‰ã‹ã«ã¤ãªã
        df_smooth = generate_smooth_curve(timestamps_hourly, levels_hourly, interval_minutes=5)
        
        return df_smooth

    def get_current_level(self, df_fine):
        now_jst = datetime.datetime.now(datetime.timezone.utc) + datetime.timedelta(hours=9)
        now_naive = now_jst.replace(tzinfo=None)
        
        if df_fine.empty or now_naive < df_fine['time'].iloc[0] or now_naive > df_fine['time'].iloc[-1]:
            # ç¯„å›²å¤–ãªã‚‰æ•°å¼ã§ç®—å‡º
            return now_naive, self.get_backup_level(now_naive) + self.total_level_offset
            
        idx = (df_fine['time'] - now_naive).abs().idxmin()
        return now_naive, df_fine.loc[idx, 'level']

# ---------------------------------------------------------
# 7. ãƒ¡ã‚¤ãƒ³å‡¦ç† & UI
# ---------------------------------------------------------
if 'view_date' not in st.session_state:
    now_jst = datetime.datetime.now(datetime.timezone.utc) + datetime.timedelta(hours=9)
    if now_jst.year != 2026:
        st.session_state['view_date'] = datetime.date(2026, 1, 9)
    else:
        st.session_state['view_date'] = now_jst.date()

view_date = st.session_state['view_date']
st.markdown("<h5 style='margin-bottom:5px;'>âš“ Onishi Port (Smoothed)</h5>", unsafe_allow_html=True)

# ãƒ‡ãƒ¼ã‚¿æº–å‚™
current_pressure = get_current_pressure()
model = JMATideModel(pressure_hpa=current_pressure, year=2026)

# ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ (5æ—¥åˆ†)
df = model.get_dataframe(view_date, days=5)

curr_time, curr_lvl = model.get_current_level(df)
ma = get_moon_age(view_date)
tn = get_tide_name(ma)

# è£œæ­£æƒ…å ±ã®è¡¨ç¤º
p_diff = int(1013 - current_pressure)
adj_txt = f"+{p_diff}" if p_diff > 0 else f"{p_diff}"
total_adj = model.total_level_offset
base_adj_txt = f"+{LEVEL_BASE_OFFSET}"

st.markdown(f"""
<div style="font-size:0.85rem; background:#f8f9fa; padding:8px; border:1px solid #ddd; margin-bottom:5px; border-radius:4px;">
 <div><b>Period:</b> {view_date.strftime('%m/%d')}~ (5 Days) <span style="color:#555;">(Moon:{ma:.1f} {tn})</span></div>
 <div style="margin-top:2px;">
   <span style="color:#0066cc; font-weight:bold;">Now: {curr_time.strftime('%H:%M')} {int(curr_lvl)}cm</span>
   <span style="font-size:0.75rem; color:#666; margin-left:5px;">
    (Press:{int(current_pressure)}hPa <span style="color:#d62728;">Adj:{adj_txt}cm</span> + Base:{base_adj_txt}cm = Total <span style="color:#2ca02c;">+{total_adj}cm</span>)
   </span>
 </div>
</div>
""", unsafe_allow_html=True)

# ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³
c1, c2 = st.columns([1,1])
if c1.button("< Prev 5 Days"): st.session_state['view_date'] -= datetime.timedelta(days=5)
if c2.button("Next 5 Days >"): st.session_state['view_date'] += datetime.timedelta(days=5)

# ã‚µã‚¤ãƒ‰ãƒãƒ¼
with st.sidebar:
    st.header("âš™ï¸ Settings")
    st.info(f"ğŸ“¡ API Status: OK\nPressure: {current_pressure} hPa")
    st.markdown("---")
    target_cm = st.number_input("Limit (cm)", value=120, step=10)
    start_h, end_h = st.slider("Hours", 0, 24, (7, 23))
    st.markdown("---")
    if st.button("Reset to 2026/1/9"): st.session_state['view_date'] = datetime.date(2026, 1, 9)

# è§£æ
df['hour'] = df['time'].dt.hour
df['is_safe'] = (df['level'] <= target_cm) & (df['hour'] >= start_h) & (df['hour'] < end_h)

# ä½œæ¥­å¯èƒ½æ™‚é–“ã®æŠ½å‡º
safe_windows = []
if df['is_safe'].any():
    df['grp'] = (df['is_safe'] != df['is_safe'].shift()).cumsum()
    for _, g in df[df['is_safe']].groupby('grp'):
        s, e = g['time'].iloc[0], g['time'].iloc[-1]
        
        if (e-s).total_seconds() >= 600:
            min_l = g['level'].min()
            min_t = g.loc[g['level'].idxmin(), 'time']
            d = e - s
            h, m = d.seconds//3600, (d.seconds%3600)//60
            
            safe_windows.append({
                "date": s.strftime('%m/%d(%a)'),
                "start": s.strftime("%H:%M"),
                "end": e.strftime("%H:%M"),
                "dur": f"{h}:{m:02}",
                "gl": f"Work\n{h}:{m:02}",
                "mt": min_t, "ml": min_l
            })

# ãƒ”ãƒ¼ã‚¯æ¤œå‡º (æ¥µå¤§ãƒ»æ¥µå°) - è¿‘å‚æ¢ç´¢
# è£œé–“ãƒ‡ãƒ¼ã‚¿ãªã®ã§å˜ç´”æ¯”è¼ƒã§OK
# ãƒã‚¤ã‚ºé™¤å»ã®ãŸã‚å°‘ã—é–“å¼•ã
peak_window = 12 # 5åˆ†é–“éš”x12 = 60åˆ†ä»¥å†…ã®æ¥µå€¤ã‚’æ¢ã™
df['is_high'] = False
df['is_low'] = False

# ç°¡æ˜“çš„ãªãƒ”ãƒ¼ã‚¯æ¤œå‡ºãƒ­ã‚¸ãƒƒã‚¯ (Scipy find_peaksãªã—)
levels = df['level'].values
for i in range(peak_window, len(levels)-peak_window):
    window = levels[i-peak_window : i+peak_window+1]
    center = levels[i]
    if center == np.max(window) and center > 150: # æº€æ½®é–¾å€¤
        df.at[i, 'is_high'] = True
    if center == np.min(window) and center < 250: # å¹²æ½®é–¾å€¤
        df.at[i, 'is_low'] = True

highs = df[df['is_high']].copy()
lows = df[df['is_low']].copy()
highs = deduplicate_peaks(highs)
lows = deduplicate_peaks(lows)

# ---------------------------------------------------------
# 8. ã‚°ãƒ©ãƒ•æç”» (Matplotlib)
# ---------------------------------------------------------
fig, ax = plt.subplots(figsize=(10, 5))

# ãƒ¡ã‚¤ãƒ³æ½®ä½ç·š
ax.plot(df['time'], df['level'], '#0066cc', lw=2, zorder=2, label="Tide Level")

# åˆ¶é™ãƒ©ã‚¤ãƒ³
ax.axhline(target_cm, c='orange', ls='--', lw=1.5, label='Limit')

# ä½œæ¥­å¯èƒ½ã‚¨ãƒªã‚¢ã®å¡—ã‚Šã¤ã¶ã—
ax.fill_between(df['time'], df['level'], target_cm, where=df['is_safe'], color='#ffcc00', alpha=0.4)

# ç¾åœ¨ä½ç½®
gs, ge = df['time'].iloc[0], df['time'].iloc[-1]
if gs <= curr_time <= ge:
    ax.scatter(curr_time, curr_lvl, c='gold', edgecolors='black', s=90, zorder=10, label="Now")

# æº€æ½® (èµ¤ â–²)
for _, r in highs.iterrows():
    ax.scatter(r['time'], r['level'], c='red', marker='^', s=40, zorder=3)
    off = 15 if r['time'].day % 2 == 0 else 35
    ax.annotate(f"{r['time'].strftime('%H:%M')}\n{int(r['level'])}", 
                (r['time'], r['level']), xytext=(0,off), textcoords='offset points', 
                ha='center', fontsize=8, color='#cc0000', fontweight='bold')

# å¹²æ½® (é’ â–¼)
for _, r in lows.iterrows():
    ax.scatter(r['time'], r['level'], c='blue', marker='v', s=40, zorder=3)
    off = -25 if r['time'].day % 2 == 0 else -45
    ax.annotate(f"{r['time'].strftime('%H:%M')}\n{int(r['level'])}", 
                (r['time'], r['level']), xytext=(0,off), textcoords='offset points', 
                ha='center', fontsize=8, color='#0000cc', fontweight='bold')

# ä½œæ¥­æ™‚é–“ã®æ³¨é‡ˆ
for w in safe_windows:
    ax.annotate(w['gl'], (w['mt'], w['ml']), xytext=(0,-85), textcoords='offset points', 
                ha='center', fontsize=8, color='#b8860b', fontweight='bold', 
                bbox=dict(boxstyle="square,pad=0.1", fc="white", ec="none", alpha=0.7))

ax.set_ylabel("Level (cm)")
ax.grid(True, ls=':', alpha=0.6)
ax.xaxis.set_major_formatter(mdates.DateFormatter('%m/%d\n(%a)'))

# Yè»¸ã®ãƒãƒ¼ã‚¸ãƒ³èª¿æ•´ (ã‚°ãƒ©ãƒ•ãŒè¦‹åˆ‡ã‚Œãªã„ã‚ˆã†ã«)
y_min, y_max = df['level'].min(), df['level'].max()
ax.set_ylim(bottom=y_min - 20, top=y_max + 50) 

plt.tight_layout()
st.pyplot(fig)

# ---------------------------------------------------------
# 9. ä½œæ¥­æ™‚é–“ãƒªã‚¹ãƒˆ
# ---------------------------------------------------------
st.markdown("---")
st.markdown(f"##### ğŸ“‹ Workable Time List (Limit <= {target_cm}cm)")

if safe_windows:
    rdf = pd.DataFrame(safe_windows)
    cols = ["date", "start", "end", "dur"]
    cc = st.columns(3)
    chunks = np.array_split(rdf, 3)
    for i, col in enumerate(cc):
        if i < len(chunks) and not chunks[i].empty:
            col.dataframe(chunks[i][cols], hide_index=True, use_container_width=True)
else:
    st.warning("No workable time found in this period.")
