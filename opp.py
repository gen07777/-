import streamlit as st
import requests
import datetime
from datetime import timedelta
import pandas as pd
import numpy as np

# ==========================================
# è¨­å®šã‚¨ãƒªã‚¢
# ==========================================
OPENWEATHER_API_KEY = "f8b87c403597b305f1bbf48a3bdf8dcb"
STATION_CODE = "344311"  # ç«¹åŸ
TARGET_YEAR = 2026       # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå¹´

# å¤§è¥¿æ¸¯ è£œæ­£å®šæ•°
TIME_OFFSET_MIN = 1       # æ™‚é–“è£œæ­£ +1åˆ†
LEVEL_BASE_OFFSET = 13    # åŸºæº–é¢è£œæ­£ +13cm
STANDARD_PRESSURE = 1013  # æ¨™æº–æ°—åœ§

# ==========================================
# 1. ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ã‚¿ & ãƒ‡ãƒ¼ã‚¿è£œå®Œ
# ==========================================
# åŸºæº–ã¨ãªã‚‹ãƒ‡ãƒ¼ã‚¿ï¼ˆ1æœˆ9æ—¥ï¼‰
BASE_BACKUP_DATA = [230, 275, 290, 265, 210, 140, 70, 30, 40, 100, 180, 260, 315, 330, 300, 240, 170, 110, 80, 85, 130, 190, 250, 290]

def get_fallback_data(date_str):
    """
    ãƒ‡ãƒ¼ã‚¿ãŒãªã„æ—¥ã§ã‚‚ãƒ‡ãƒ¢ç”¨ã«ãã‚Œã£ã½ã„ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°
    ï¼ˆåŸºæº–ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ¯æ—¥ç´„50åˆ†ãšã¤æ™‚é–“ã‚’ãšã‚‰ã—ã¦ç”Ÿæˆï¼‰
    """
    # ç°¡æ˜“ãƒ­ã‚¸ãƒƒã‚¯: æ—¥ä»˜ã®å·®åˆ†ã‚’è¨ˆç®—
    base_date = datetime.date(2026, 1, 9)
    try:
        target = datetime.datetime.strptime(date_str, "%Y-%m-%d").date()
        diff_days = (target - base_date).days
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’å›è»¢ï¼ˆã‚·ãƒ•ãƒˆï¼‰ã•ã›ã¦ç–‘ä¼¼ç”Ÿæˆ
        # 1æ—¥ã‚ãŸã‚Šç´„50åˆ†(ãƒ‡ãƒ¼ã‚¿é…åˆ—ã®indexã§ã„ã†ã¨ç´„0.8å€‹åˆ†)ã‚ºãƒ¬ã‚‹ãŒã€
        # ã“ã“ã§ã¯ç°¡æ˜“çš„ã«1æ™‚é–“(index 1)ãšã¤ãšã‚‰ã—ã¦ãƒ‡ãƒ¢è¡¨ç¤ºã™ã‚‹
        shift = diff_days * 1 
        data = BASE_BACKUP_DATA
        
        # é…åˆ—ã‚’å›è»¢
        num_items = len(data)
        shifted_data = [data[(i - shift) % num_items] for i in range(num_items)]
        return shifted_data
    except:
        return BASE_BACKUP_DATA

# ==========================================
# 2. ãƒ‡ãƒ¼ã‚¿å–å¾— & è§£æãƒ­ã‚¸ãƒƒã‚¯
# ==========================================
@st.cache_data(ttl=3600)
def fetch_jma_tide_data(year, station_code):
    """æ°—è±¡åºã‹ã‚‰å¹´é–“ã®å…¨ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
    url = f"https://www.data.jma.go.jp/kaiyou/data/db/tide/suisan/txt/{year}/{station_code}.txt"
    headers = {
        "User-Agent": "Mozilla/5.0"
    }
    
    data_map = {}
    try:
        response = requests.get(url, headers=headers, timeout=5)
        response.encoding = 'utf-8'
        if response.status_code == 200:
            lines = response.text.splitlines()
            for line in lines:
                parts = line.split()
                if len(parts) < 28 or not parts[0].isdigit():
                    continue
                m_month = int(parts[2])
                m_day   = int(parts[3])
                d_str = f"{year}-{m_month:02d}-{m_day:02d}"
                hourly_levels = [int(h) for h in parts[4:28]]
                data_map[d_str] = hourly_levels
    except Exception:
        pass
    
    return data_map

def get_current_pressure():
    lat, lon = 34.23, 132.83
    url = f"https://api.openweathermap.org/data/2.5/weather?lat={lat}&lon={lon}&appid={OPENWEATHER_API_KEY}&units=metric&lang=ja"
    try:
        res = requests.get(url, timeout=3)
        if res.status_code == 200:
            return res.json()["main"]["pressure"]
    except Exception:
        pass
    return STANDARD_PRESSURE

# ==========================================
# 3. è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯
# ==========================================
def process_daily_data(date_obj, hourly_tides, work_threshold, start_h, end_h, total_correction):
    """1æ—¥åˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã—ã¦ã€ä½œæ¥­æ™‚é–“ã¨ã‚°ãƒ©ãƒ•ç”¨ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™"""
    
    # æ½®ä½è£œæ­£
    corrected_levels = [h + total_correction for h in hourly_tides]
    
    # --- ä½œæ¥­å¯èƒ½æ™‚é–“ã®è¨ˆç®— ---
    workable_ranges = []
    is_working = False
    start_time = None
    
    for h in range(24):
        # ä½œæ¥­æ™‚é–“æ å¤–ãƒã‚§ãƒƒã‚¯
        if h < start_h or h > end_h:
            if is_working:
                workable_ranges.append(f"{start_time:02d}:00 ï½ {h:02d}:00")
                is_working = False
            continue
            
        level = corrected_levels[h]
        if level <= work_threshold:
            if not is_working:
                is_working = True
                start_time = h
        else:
            if is_working:
                workable_ranges.append(f"{start_time:02d}:00 ï½ {h:02d}:00")
                is_working = False
                
    if is_working:
        end_display = end_h + 1 if end_h < 23 else 24
        workable_ranges.append(f"{start_time:02d}:00 ï½ {end_display:02d}:00")

    # --- æº€å¹²æ½®ã®ç‰¹å®š ---
    peaks = []
    for i in range(1, 23):
        prev, curr, next_val = corrected_levels[i-1], corrected_levels[i], corrected_levels[i+1]
        
        # æ™‚é–“è£œæ­£ (+1åˆ†)
        total_m = i * 60 + TIME_OFFSET_MIN
        time_str = f"{(total_m // 60):02d}:{total_m % 60:02d}"
        
        if prev < curr and curr >= next_val:
            peaks.append(f"æº€ {time_str} ({curr}cm)")
        elif prev > curr and curr <= next_val:
            peaks.append(f"å¹² {time_str} ({curr}cm)")

    return {
        "date": date_obj,
        "levels": corrected_levels,
        "work_ranges": workable_ranges,
        "peaks": peaks
    }

# ==========================================
# 4. ãƒ¡ã‚¤ãƒ³ç”»é¢
# ==========================================
def main():
    st.set_page_config(page_title="å¤§è¥¿æ¸¯ é€±é–“æ½®æ±", page_icon="âš“")
    st.title("âš“ å¤§è¥¿æ¸¯ (å¤§å´ä¸Šå³¶) é€±é–“æ½®æ±")
    
    # --- ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š ---
    with st.sidebar:
        st.header("âš™ï¸ è¨­å®š")
        default_date = datetime.date(2026, 1, 9)
        selected_date = st.date_input("é–‹å§‹æ—¥", default_date)
        
        st.divider()
        st.subheader("ğŸ›  ä½œæ¥­æ¡ä»¶")
        work_threshold = st.slider("æ½®ä½ãƒ©ã‚¤ãƒ³ (cmä»¥ä¸‹)", 0, 400, 120)
        work_time_range = st.slider("ä½œæ¥­æ™‚é–“å¸¯", 0, 24, (7, 23))
        start_h, end_h = work_time_range

    # --- ãƒ‡ãƒ¼ã‚¿æº–å‚™ ---
    tide_db = fetch_jma_tide_data(TARGET_YEAR, STATION_CODE)
    current_hpa = get_current_pressure()
    pressure_diff = STANDARD_PRESSURE - current_hpa
    total_level_correction = LEVEL_BASE_OFFSET + pressure_diff

    # --- ãƒ˜ãƒƒãƒ€ãƒ¼æƒ…å ± ---
    c1, c2 = st.columns(2)
    c1.metric("ç¾åœ¨æ°—åœ§", f"{current_hpa} hPa")
    c2.metric("è£œæ­£å€¤", f"{total_level_correction:+} cm", help="åŸºæº–13cm + æ°—åœ§å·®")
    st.divider()

    # --- 5æ—¥åˆ†ã®ãƒ‡ãƒ¼ã‚¿å‡¦ç† ---
    five_days_results = []
    graph_data_list = []
    
    for i in range(5):
        target_date = selected_date + timedelta(days=i)
        d_str = target_date.strftime("%Y-%m-%d")
        
        # ãƒ‡ãƒ¼ã‚¿å–å¾— (ãªã‘ã‚Œã°è£œå®Œãƒ‡ãƒ¼ã‚¿)
        if tide_db and d_str in tide_db:
            hourly = tide_db[d_str]
        else:
            hourly = get_fallback_data(d_str)
            
        # è¨ˆç®—å®Ÿè¡Œ
        res = process_daily_data(target_date, hourly, work_threshold, start_h, end_h, total_level_correction)
        five_days_results.append(res)
        
        # ã‚°ãƒ©ãƒ•ç”¨ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ (æ—¥æ™‚index)
        for hour, level in enumerate(res["levels"]):
            dt = datetime.datetime.combine(target_date, datetime.time(hour, 0))
            graph_data_list.append({
                "æ—¥æ™‚": dt,
                "äºˆæ¸¬æ½®ä½": level,
                "ä½œæ¥­ãƒ©ã‚¤ãƒ³": work_threshold
            })

    # ==========================================
    # è¡¨ç¤º 1: 5æ—¥é–“ã®é€£ç¶šã‚°ãƒ©ãƒ• (ãƒˆãƒƒãƒ—é…ç½®)
    # ==========================================
    st.subheader(f"ğŸ“ˆ 5æ—¥é–“ã®æ½®æ±ã‚°ãƒ©ãƒ• ({selected_date.strftime('%m/%d')} ï½)")
    
    df_graph = pd.DataFrame(graph_data_list).set_index("æ—¥æ™‚")
    st.line_chart(
        df_graph,
        color=["#0000FF", "#FF0000"],
        height=300 
    )

    # ==========================================
    # è¡¨ç¤º 2: æ—¥åˆ¥ãƒªã‚¹ãƒˆ (å°åˆ·ãƒ»ã‚¹ãƒãƒ›ç”¨)
    # ==========================================
    st.subheader("ğŸ“‹ æ—¥åˆ¥ ä½œæ¥­å¯èƒ½æ™‚é–“ & æ½®æ±")
    st.caption(f"æ¡ä»¶: {start_h}:00-{end_h}:00 ã®é–“ã§ {work_threshold}cm ä»¥ä¸‹")

    for day_res in five_days_results:
        # æ—¥ä»˜ãƒ˜ãƒƒãƒ€ãƒ¼
        date_text = day_res["date"].strftime("%m/%d (%a)")
        
        with st.container():
            st.markdown(f"### {date_text}")
            
            col_a, col_b = st.columns([1, 1])
            
            # å·¦: ä½œæ¥­æ™‚é–“
            with col_a:
                st.markdown("**âœ… ä½œæ¥­å¯èƒ½**")
                if day_res["work_ranges"]:
                    for r in day_res["work_ranges"]:
                        st.success(f"ğŸ•’ {r}")
                else:
                    st.warning("ãªã—")
            
            # å³: æº€å¹²æ½®
            with col_b:
                st.markdown("**ğŸŒŠ æº€æ½®ãƒ»å¹²æ½®**")
                for p in day_res["peaks"]:
                    st.text(p)
            
            st.markdown("---") # åŒºåˆ‡ã‚Šç·š

if __name__ == "__main__":
    main()
